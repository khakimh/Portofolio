{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create machine learning model to predict news title. You can do prediction using this model through API. You can see the API documentation in the end of page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('News Title.xls')\n",
    "df = df.drop('No', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Title</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google+ rolls out 'Stories' for tricked out ph...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dov Charney's Redeeming Quality</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White God adds Un Certain Regard to the Palm Dog</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google shows off Androids for wearables, cars,...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China May new bank loans at 870.8 bln yuan</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65530</th>\n",
       "      <td>Xbox One Homebrew Will Likely Be a Reality in ...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65531</th>\n",
       "      <td>Maker Recalls 1.9 Million Rear-Facing Infant S...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65532</th>\n",
       "      <td>Watch first 'Ninja Turtles' trailer</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65533</th>\n",
       "      <td>23/05/2014Dogs triumph in Cannes as canine thr...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65534</th>\n",
       "      <td>FrontPoint Security CEO Chris Villar Ranked No...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65535 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              News Title       Category\n",
       "0      Google+ rolls out 'Stories' for tricked out ph...     Technology\n",
       "1                        Dov Charney's Redeeming Quality       Business\n",
       "2       White God adds Un Certain Regard to the Palm Dog  Entertainment\n",
       "3      Google shows off Androids for wearables, cars,...     Technology\n",
       "4             China May new bank loans at 870.8 bln yuan       Business\n",
       "...                                                  ...            ...\n",
       "65530  Xbox One Homebrew Will Likely Be a Reality in ...     Technology\n",
       "65531  Maker Recalls 1.9 Million Rear-Facing Infant S...     Technology\n",
       "65532                Watch first 'Ninja Turtles' trailer  Entertainment\n",
       "65533  23/05/2014Dogs triumph in Cannes as canine thr...  Entertainment\n",
       "65534  FrontPoint Security CEO Chris Villar Ranked No...       Business\n",
       "\n",
       "[65535 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df['Category'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>23961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>17707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>16776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical</th>\n",
       "      <td>7091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category\n",
       "Entertainment     23961\n",
       "Business          17707\n",
       "Technology        16776\n",
       "Medical            7091"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: \n",
    "* It seem that imbalance class for the category. So we are going to calculate the class weight so we can use it on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Class Weight'] = df1['Category'].apply(\n",
    "    lambda row : round(df.shape[0]/row,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Class Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>23961</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>17707</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>16776</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical</th>\n",
       "      <td>7091</td>\n",
       "      <td>9.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category  Class Weight\n",
       "Entertainment     23961          2.74\n",
       "Business          17707          3.70\n",
       "Technology        16776          3.91\n",
       "Medical            7091          9.24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Title</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google+ rolls out 'Stories' for tricked out ph...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dov Charney's Redeeming Quality</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White God adds Un Certain Regard to the Palm Dog</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google shows off Androids for wearables, cars,...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China May new bank loans at 870.8 bln yuan</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Firefox Windows 8 Metro Browser Development Ca...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Destiny Beta Kicks Off In July</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple &amp; Google's Motorola end legal battle</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UPDATE 2-Facebook Q1 revenue grows 72 percent ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Selena Gomez, Justin Bieber Spotted at the Sam...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Titanfall: Gameplay basics, release date, DLC ...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Angela Bassett to direct Whitney Houston biopi...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>German Museum Lets You Talk to van Gogh's Regr...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iraq crisis fuels concern for oil prices</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BC doctor OK, not in quarantine after Ebola ai...</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GM recalling nearly 29000 Chevrolet Cruzes to ...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Local Experts Weigh in on Climate Change</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Samsung Reportedly Explored Acquiring Company ...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'Ghost Stories' by Coldplay Hits No. 1 on Bill...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hackers raid eBay, access 145 million records</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           News Title       Category\n",
       "0   Google+ rolls out 'Stories' for tricked out ph...     Technology\n",
       "1                     Dov Charney's Redeeming Quality       Business\n",
       "2    White God adds Un Certain Regard to the Palm Dog  Entertainment\n",
       "3   Google shows off Androids for wearables, cars,...     Technology\n",
       "4          China May new bank loans at 870.8 bln yuan       Business\n",
       "5   Firefox Windows 8 Metro Browser Development Ca...     Technology\n",
       "6                      Destiny Beta Kicks Off In July     Technology\n",
       "7          Apple & Google's Motorola end legal battle     Technology\n",
       "8   UPDATE 2-Facebook Q1 revenue grows 72 percent ...       Business\n",
       "9   Selena Gomez, Justin Bieber Spotted at the Sam...  Entertainment\n",
       "10  Titanfall: Gameplay basics, release date, DLC ...     Technology\n",
       "11  Angela Bassett to direct Whitney Houston biopi...  Entertainment\n",
       "12  German Museum Lets You Talk to van Gogh's Regr...  Entertainment\n",
       "13           Iraq crisis fuels concern for oil prices     Technology\n",
       "14  BC doctor OK, not in quarantine after Ebola ai...        Medical\n",
       "15  GM recalling nearly 29000 Chevrolet Cruzes to ...     Technology\n",
       "16           Local Experts Weigh in on Climate Change     Technology\n",
       "17  Samsung Reportedly Explored Acquiring Company ...     Technology\n",
       "18  'Ghost Stories' by Coldplay Hits No. 1 on Bill...  Entertainment\n",
       "19      Hackers raid eBay, access 145 million records     Technology"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_text_news(data):\n",
    "    # removing punctuation\n",
    "    nopunc = [char for char in data if char not in string.punctuation]\n",
    "    data_ = ''.join(nopunc)\n",
    "    \n",
    "    # doing tokenization\n",
    "    data1 = nlp(data_)\n",
    "    data2 = [item for item in data1]\n",
    "    \n",
    "    # doing lematization\n",
    "    data3 = [item.lemma_ for item in data2]\n",
    "    \n",
    "    # removing stop word\n",
    "    data4 = [item for item in data3 if item not in nlp.Defaults.stop_words]\n",
    "    \n",
    "    return ' '.join(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['News Title Processed'] = df['News Title'].apply(processing_text_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>News Title Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google+ rolls out 'Stories' for tricked out ph...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Google roll story tricked photo playback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dov Charney's Redeeming Quality</td>\n",
       "      <td>Business</td>\n",
       "      <td>Dov charney redeem quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White God adds Un Certain Regard to the Palm Dog</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>White God add Un Certain Regard Palm Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google shows off Androids for wearables, cars,...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Google android wearable car tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China May new bank loans at 870.8 bln yuan</td>\n",
       "      <td>Business</td>\n",
       "      <td>China May new bank loan 8708 bln yuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Firefox Windows 8 Metro Browser Development Ca...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Firefox Windows 8 Metro Browser Development ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Destiny Beta Kicks Off In July</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Destiny Beta kick July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple &amp; Google's Motorola end legal battle</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Apple   Googles Motorola end legal battle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UPDATE 2-Facebook Q1 revenue grows 72 percent ...</td>\n",
       "      <td>Business</td>\n",
       "      <td>UPDATE 2Facebook Q1 revenue grow 72 percent ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Selena Gomez, Justin Bieber Spotted at the Sam...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Selena Gomez Justin Bieber spot Same Recording...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          News Title       Category  \\\n",
       "0  Google+ rolls out 'Stories' for tricked out ph...     Technology   \n",
       "1                    Dov Charney's Redeeming Quality       Business   \n",
       "2   White God adds Un Certain Regard to the Palm Dog  Entertainment   \n",
       "3  Google shows off Androids for wearables, cars,...     Technology   \n",
       "4         China May new bank loans at 870.8 bln yuan       Business   \n",
       "5  Firefox Windows 8 Metro Browser Development Ca...     Technology   \n",
       "6                     Destiny Beta Kicks Off In July     Technology   \n",
       "7         Apple & Google's Motorola end legal battle     Technology   \n",
       "8  UPDATE 2-Facebook Q1 revenue grows 72 percent ...       Business   \n",
       "9  Selena Gomez, Justin Bieber Spotted at the Sam...  Entertainment   \n",
       "\n",
       "                                News Title Processed  \n",
       "0           Google roll story tricked photo playback  \n",
       "1                         Dov charney redeem quality  \n",
       "2           White God add Un Certain Regard Palm Dog  \n",
       "3                     Google android wearable car tv  \n",
       "4              China May new bank loan 8708 bln yuan  \n",
       "5  Firefox Windows 8 Metro Browser Development ca...  \n",
       "6                             Destiny Beta kick July  \n",
       "7          Apple   Googles Motorola end legal battle  \n",
       "8  UPDATE 2Facebook Q1 revenue grow 72 percent ri...  \n",
       "9  Selena Gomez Justin Bieber spot Same Recording...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_1 = []\n",
    "dict_word_1 = {}\n",
    "for item1 in df[df['Category'] == 'Technology']['News Title Processed']:\n",
    "    for item2 in item1.split(' '):\n",
    "        if item2 not in list_word_1:\n",
    "            list_word_1.append(item2)\n",
    "            dict_word_1[item2] = 1\n",
    "        else:\n",
    "            dict_word_1[item2] += 1\n",
    "df1 = pd.DataFrame([[key,val] for key, val in dict_word_1.items()], columns=['Technology','#'])\n",
    "df1 = df1[(df1['Technology'] != '') & (df1['Technology'] != '-PRON-') & (df1['Technology'] != '\\t')]\n",
    "df1 = df1.sort_values('#', ascending=False).head(10)\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_2 = []\n",
    "dict_word_2 = {}\n",
    "for item1 in df[df['Category'] == 'Business']['News Title Processed']:\n",
    "    for item2 in item1.split(' '):\n",
    "        if item2 not in list_word_2:\n",
    "            list_word_2.append(item2)\n",
    "            dict_word_2[item2] = 1\n",
    "        else:\n",
    "            dict_word_2[item2] += 1\n",
    "df2 = pd.DataFrame([[key,val] for key, val in dict_word_2.items()], columns=['Business','#'])\n",
    "df2 = df2[(df2['Business'] != '') & (df2['Business'] != '-PRON-') & (df2['Business'] != '\\t')]\n",
    "df2 = df2.sort_values('#', ascending=False).head(10)\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_3 = []\n",
    "dict_word_3 = {}\n",
    "for item1 in df[df['Category'] == 'Entertainment']['News Title Processed']:\n",
    "    for item2 in item1.split(' '):\n",
    "        if item2 not in list_word_3:\n",
    "            list_word_3.append(item2)\n",
    "            dict_word_3[item2] = 1\n",
    "        else:\n",
    "            dict_word_3[item2] += 1\n",
    "df3 = pd.DataFrame([[key,val] for key, val in dict_word_3.items()], columns=['Entertainment','#'])\n",
    "df3 = df3[(df3['Entertainment'] != '') & (df3['Entertainment'] != '-PRON-') & (df3['Entertainment'] != '\\t')]\n",
    "df3 = df3.sort_values('#', ascending=False).head(10)\n",
    "df3 = df3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_4 = []\n",
    "dict_word_4 = {}\n",
    "for item1 in df[df['Category'] == 'Medical']['News Title Processed']:\n",
    "    for item2 in item1.split(' '):\n",
    "        if item2 not in list_word_4:\n",
    "            list_word_4.append(item2)\n",
    "            dict_word_4[item2] = 1\n",
    "        else:\n",
    "            dict_word_4[item2] += 1\n",
    "df4 = pd.DataFrame([[key,val] for key, val in dict_word_4.items()], columns=['Medical','#'])\n",
    "df4 = df4[(df4['Medical'] != '') & (df4['Medical'] != '-PRON-') & (df4['Medical'] != '\\t')]\n",
    "df4 = df4.sort_values('#', ascending=False).head(10)\n",
    "df4 = df4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Word by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technology</th>\n",
       "      <th>#</th>\n",
       "      <th>Business</th>\n",
       "      <th>#</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>#</th>\n",
       "      <th>Medical</th>\n",
       "      <th>#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>1539</td>\n",
       "      <td>US</td>\n",
       "      <td>1646</td>\n",
       "      <td>Kim</td>\n",
       "      <td>887</td>\n",
       "      <td>Ebola</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>1180</td>\n",
       "      <td>stock</td>\n",
       "      <td>728</td>\n",
       "      <td>New</td>\n",
       "      <td>846</td>\n",
       "      <td>study</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>1052</td>\n",
       "      <td>China</td>\n",
       "      <td>576</td>\n",
       "      <td>Kardashian</td>\n",
       "      <td>783</td>\n",
       "      <td>cancer</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Galaxy</td>\n",
       "      <td>876</td>\n",
       "      <td>rise</td>\n",
       "      <td>516</td>\n",
       "      <td>2014</td>\n",
       "      <td>759</td>\n",
       "      <td>US</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>764</td>\n",
       "      <td>rate</td>\n",
       "      <td>504</td>\n",
       "      <td>\"</td>\n",
       "      <td>758</td>\n",
       "      <td>case</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>693</td>\n",
       "      <td>price</td>\n",
       "      <td>498</td>\n",
       "      <td>video</td>\n",
       "      <td>697</td>\n",
       "      <td>health</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new</td>\n",
       "      <td>675</td>\n",
       "      <td>sale</td>\n",
       "      <td>480</td>\n",
       "      <td>Game</td>\n",
       "      <td>621</td>\n",
       "      <td>FDA</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Android</td>\n",
       "      <td>615</td>\n",
       "      <td>deal</td>\n",
       "      <td>459</td>\n",
       "      <td>new</td>\n",
       "      <td>611</td>\n",
       "      <td>new</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New</td>\n",
       "      <td>575</td>\n",
       "      <td>high</td>\n",
       "      <td>456</td>\n",
       "      <td>season</td>\n",
       "      <td>603</td>\n",
       "      <td>find</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>launch</td>\n",
       "      <td>485</td>\n",
       "      <td>billion</td>\n",
       "      <td>443</td>\n",
       "      <td>Star</td>\n",
       "      <td>591</td>\n",
       "      <td>death</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Technology     # Business     # Entertainment    # Medical    #\n",
       "0     Google  1539       US  1646           Kim  887   Ebola  574\n",
       "1      Apple  1180    stock   728           New  846   study  370\n",
       "2    Samsung  1052    China   576    Kardashian  783  cancer  351\n",
       "3     Galaxy   876     rise   516          2014  759      US  338\n",
       "4  Microsoft   764     rate   504             \"  758    case  246\n",
       "5   Facebook   693    price   498         video  697  health  244\n",
       "6        new   675     sale   480          Game  621     FDA  227\n",
       "7    Android   615     deal   459           new  611     new  213\n",
       "8        New   575     high   456        season  603    find  203\n",
       "9     launch   485  billion   443          Star  591   death  203"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df1, df2, df3, df4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: \n",
    "* As we can see that almost every category have different top 10 appeared word except for word \"US\" appear twice in \"Business\" and \"Medical\". Let's look at the top bigram by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_1 = []\n",
    "dict_word_1 = {}\n",
    "for item1 in df[df['Category'] == 'Technology']['News Title Processed']:\n",
    "    words = re.findall(\"\\w+\",item1)\n",
    "    for item in zip(words, islice(words, 1, None)):\n",
    "        bigram = item[0] + '_' + item[1]\n",
    "        if bigram not in list_word_1:\n",
    "            list_word_1.append(bigram)\n",
    "            dict_word_1[bigram] = 1 \n",
    "        else:\n",
    "            dict_word_1[bigram] += 1\n",
    "df1 = pd.DataFrame([[key,val] for key, val in dict_word_1.items()], columns=['Technology','#'])\n",
    "df1 = df1[(df1['Technology'] != '') & (df1['Technology'] != '-PRON-') & (df1['Technology'] != '\\t')]\n",
    "df1 = df1.sort_values('#', ascending=False).head(10)\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_2 = []\n",
    "dict_word_2 = {}\n",
    "for item1 in df[df['Category'] == 'Business']['News Title Processed']:\n",
    "    words = re.findall(\"\\w+\",item1)\n",
    "    for item in zip(words, islice(words, 1, None)):\n",
    "        bigram = item[0] + '_' + item[1]\n",
    "        if bigram not in list_word_2:\n",
    "            list_word_2.append(bigram)\n",
    "            dict_word_2[bigram] = 1 \n",
    "        else:\n",
    "            dict_word_2[bigram] += 1\n",
    "df2 = pd.DataFrame([[key,val] for key, val in dict_word_2.items()], columns=['Business','#'])\n",
    "df2 = df2[(df2['Business'] != '') & (df2['Business'] != '-PRON-') & (df2['Business'] != '\\t')]\n",
    "df2 = df2.sort_values('#', ascending=False).head(10)\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_3 = []\n",
    "dict_word_3 = {}\n",
    "for item1 in df[df['Category'] == 'Entertainment']['News Title Processed']:\n",
    "    words = re.findall(\"\\w+\",item1)\n",
    "    for item in zip(words, islice(words, 1, None)):\n",
    "        bigram = item[0] + '_' + item[1]\n",
    "        if bigram not in list_word_3:\n",
    "            list_word_3.append(bigram)\n",
    "            dict_word_3[bigram] = 1 \n",
    "        else:\n",
    "            dict_word_3[bigram] += 1\n",
    "df3 = pd.DataFrame([[key,val] for key, val in dict_word_3.items()], columns=['Entertainment','#'])\n",
    "df3 = df3[(df3['Entertainment'] != '') & (df3['Entertainment'] != '-PRON-') & (df3['Entertainment'] != '\\t')]\n",
    "df3 = df3.sort_values('#', ascending=False).head(10)\n",
    "df3 = df3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_4 = []\n",
    "dict_word_4 = {}\n",
    "for item1 in df[df['Category'] == 'Medical']['News Title Processed']:\n",
    "    words = re.findall(\"\\w+\",item1)\n",
    "    for item in zip(words, islice(words, 1, None)):\n",
    "        bigram = item[0] + '_' + item[1]\n",
    "        if bigram not in list_word_4:\n",
    "            list_word_4.append(bigram)\n",
    "            dict_word_4[bigram] = 1 \n",
    "        else:\n",
    "            dict_word_4[bigram] += 1\n",
    "df4 = pd.DataFrame([[key,val] for key, val in dict_word_4.items()], columns=['Medical','#'])\n",
    "df4 = df4[(df4['Medical'] != '') & (df4['Medical'] != '-PRON-') & (df4['Medical'] != '\\t')]\n",
    "df4 = df4.sort_values('#', ascending=False).head(10)\n",
    "df4 = df4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Bigram by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technology</th>\n",
       "      <th>#</th>\n",
       "      <th>Business</th>\n",
       "      <th>#</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>#</th>\n",
       "      <th>Medical</th>\n",
       "      <th>#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung_Galaxy</td>\n",
       "      <td>564</td>\n",
       "      <td>Wall_Street</td>\n",
       "      <td>167</td>\n",
       "      <td>Kim_Kardashian</td>\n",
       "      <td>597</td>\n",
       "      <td>Ebola_outbreak</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Galaxy_s5</td>\n",
       "      <td>347</td>\n",
       "      <td>US_stock</td>\n",
       "      <td>140</td>\n",
       "      <td>Game_Thrones</td>\n",
       "      <td>571</td>\n",
       "      <td>West_Nile</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google_Glass</td>\n",
       "      <td>277</td>\n",
       "      <td>Malaysia_Airlines</td>\n",
       "      <td>97</td>\n",
       "      <td>Miley_Cyrus</td>\n",
       "      <td>436</td>\n",
       "      <td>West_Africa</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climate_change</td>\n",
       "      <td>221</td>\n",
       "      <td>SP_500</td>\n",
       "      <td>82</td>\n",
       "      <td>Star_Wars</td>\n",
       "      <td>363</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iPhone_6</td>\n",
       "      <td>182</td>\n",
       "      <td>New_York</td>\n",
       "      <td>76</td>\n",
       "      <td>Justin_Bieber</td>\n",
       "      <td>353</td>\n",
       "      <td>study_find</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gas_price</td>\n",
       "      <td>153</td>\n",
       "      <td>gas_price</td>\n",
       "      <td>75</td>\n",
       "      <td>Kanye_West</td>\n",
       "      <td>330</td>\n",
       "      <td>Saudi_Arabia</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Galaxy_Tab</td>\n",
       "      <td>128</td>\n",
       "      <td>candy_crush</td>\n",
       "      <td>75</td>\n",
       "      <td>Jay_Z</td>\n",
       "      <td>276</td>\n",
       "      <td>death_toll</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Galaxy_Note</td>\n",
       "      <td>114</td>\n",
       "      <td>home_sale</td>\n",
       "      <td>73</td>\n",
       "      <td>Selena_Gomez</td>\n",
       "      <td>205</td>\n",
       "      <td>blood_test</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pro_3</td>\n",
       "      <td>107</td>\n",
       "      <td>Hong_Kong</td>\n",
       "      <td>73</td>\n",
       "      <td>Kardashian_Kanye</td>\n",
       "      <td>191</td>\n",
       "      <td>skin_cancer</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HTC_One</td>\n",
       "      <td>103</td>\n",
       "      <td>interest_rate</td>\n",
       "      <td>71</td>\n",
       "      <td>Captain_America</td>\n",
       "      <td>182</td>\n",
       "      <td>Ebola_virus</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Technology    #           Business    #     Entertainment    #  \\\n",
       "0  Samsung_Galaxy  564        Wall_Street  167    Kim_Kardashian  597   \n",
       "1       Galaxy_s5  347           US_stock  140      Game_Thrones  571   \n",
       "2    Google_Glass  277  Malaysia_Airlines   97       Miley_Cyrus  436   \n",
       "3  climate_change  221             SP_500   82         Star_Wars  363   \n",
       "4        iPhone_6  182           New_York   76     Justin_Bieber  353   \n",
       "5       gas_price  153          gas_price   75        Kanye_West  330   \n",
       "6      Galaxy_Tab  128        candy_crush   75             Jay_Z  276   \n",
       "7     Galaxy_Note  114          home_sale   73      Selena_Gomez  205   \n",
       "8           Pro_3  107          Hong_Kong   73  Kardashian_Kanye  191   \n",
       "9         HTC_One  103      interest_rate   71   Captain_America  182   \n",
       "\n",
       "          Medical    #  \n",
       "0  Ebola_outbreak  105  \n",
       "1       West_Nile   85  \n",
       "2     West_Africa   78  \n",
       "3   breast_cancer   65  \n",
       "4      study_find   63  \n",
       "5    Saudi_Arabia   61  \n",
       "6      death_toll   52  \n",
       "7      blood_test   49  \n",
       "8     skin_cancer   48  \n",
       "9     Ebola_virus   46  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df1, df2, df3, df4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: \n",
    "* We can see nicely that every category have different top 10 bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "messages_bow = CountVectorizer().fit_transform(df['News Title Processed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "messages_tfidf = TfidfTransformer().fit_transform(messages_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    "    df['News Title Processed'], df['Category'],\n",
    "    test_size = .2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modelNB = Pipeline([\n",
    "    ('bow', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelNB.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.90      0.92      0.91     14112\n",
      "Entertainment       0.94      0.98      0.96     19151\n",
      "      Medical       0.99      0.79      0.88      5725\n",
      "   Technology       0.91      0.92      0.92     13440\n",
      "\n",
      "     accuracy                           0.93     52428\n",
      "    macro avg       0.94      0.90      0.92     52428\n",
      " weighted avg       0.93      0.93      0.93     52428\n",
      "\n",
      "Accuracy =  92.71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13009</td>\n",
       "      <td>345</td>\n",
       "      <td>37</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172</td>\n",
       "      <td>18750</td>\n",
       "      <td>17</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>496</td>\n",
       "      <td>4513</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>768</td>\n",
       "      <td>325</td>\n",
       "      <td>11</td>\n",
       "      <td>12336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2      3\n",
       "0  13009    345    37    721\n",
       "1    172  18750    17    212\n",
       "2    479    496  4513    237\n",
       "3    768    325    11  12336"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "prediction = modelNB.predict(xTrain)\n",
    "print(classification_report(yTrain,prediction))\n",
    "print('Accuracy = ', round(accuracy_score(yTrain,prediction)*100,2))\n",
    "pd.DataFrame(confusion_matrix(yTrain, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.87      0.90      0.88      3595\n",
      "Entertainment       0.92      0.97      0.95      4810\n",
      "      Medical       0.97      0.73      0.84      1366\n",
      "   Technology       0.89      0.88      0.88      3336\n",
      "\n",
      "     accuracy                           0.90     13107\n",
      "    macro avg       0.91      0.87      0.89     13107\n",
      " weighted avg       0.90      0.90      0.90     13107\n",
      "\n",
      "Accuracy =  90.23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3223</td>\n",
       "      <td>112</td>\n",
       "      <td>16</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>4671</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146</td>\n",
       "      <td>151</td>\n",
       "      <td>1002</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>261</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>2931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3\n",
       "0  3223   112    16   244\n",
       "1    67  4671     8    64\n",
       "2   146   151  1002    67\n",
       "3   261   140     4  2931"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = modelNB.predict(xTest)\n",
    "print(classification_report(yTest,prediction))\n",
    "print('Accuracy = ', round(accuracy_score(yTest,prediction)*100,2))\n",
    "pd.DataFrame(confusion_matrix(yTest, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X, Y, model):\n",
    "    prediction = model.predict(X)\n",
    "    precision = precision_score(Y, prediction, average='macro') * 100\n",
    "    recall = recall_score(Y, prediction, average='macro') * 100\n",
    "    f1 = f1_score(Y, prediction, average='macro') * 100\n",
    "    accuracy = accuracy_score(Y,prediction) * 100\n",
    "    return {\n",
    "        \"f1\" : f1,\n",
    "        \"precision\" : precision,\n",
    "        \"recall\" : recall,\n",
    "        \"accuracy\" : accuracy\n",
    "    }\n",
    "\n",
    "def calculation_metrics(xTrain, yTrain, xTest, yTest, model):\n",
    "    model.fit(xTrain, yTrain)\n",
    "    train_error = evaluation(xTrain, yTrain, model)\n",
    "    validation_error = evaluation(xTest, yTest, model)\n",
    "    return train_error, validation_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "data = df['News Title Processed']\n",
    "target = df['Category']\n",
    "train_error = []\n",
    "validation_error = []\n",
    "for trainIndex, valIndex in kf.split(data, target):\n",
    "    xTrain, xTest = data.iloc[trainIndex], data.iloc[valIndex]\n",
    "    yTrain, yTest = target.iloc[trainIndex], target.iloc[valIndex]\n",
    "    \n",
    "    trainError, valError = calculation_metrics(xTrain, yTrain, xTest, yTest, modelNB)\n",
    "    \n",
    "    train_error.append(trainError)\n",
    "    validation_error.append(valError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>-</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1 Sccore</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.607940</td>\n",
       "      <td>90.317284</td>\n",
       "      <td>91.690165</td>\n",
       "      <td>92.821417</td>\n",
       "      <td>-</td>\n",
       "      <td>91.344666</td>\n",
       "      <td>87.186872</td>\n",
       "      <td>88.837091</td>\n",
       "      <td>90.341776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.494421</td>\n",
       "      <td>90.196505</td>\n",
       "      <td>91.573797</td>\n",
       "      <td>92.689171</td>\n",
       "      <td>-</td>\n",
       "      <td>91.490494</td>\n",
       "      <td>87.227714</td>\n",
       "      <td>88.897341</td>\n",
       "      <td>90.418065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.473626</td>\n",
       "      <td>90.160268</td>\n",
       "      <td>91.542717</td>\n",
       "      <td>92.667130</td>\n",
       "      <td>-</td>\n",
       "      <td>91.791245</td>\n",
       "      <td>87.717370</td>\n",
       "      <td>89.332314</td>\n",
       "      <td>90.799512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.629213</td>\n",
       "      <td>90.431155</td>\n",
       "      <td>91.774967</td>\n",
       "      <td>92.840067</td>\n",
       "      <td>-</td>\n",
       "      <td>90.709453</td>\n",
       "      <td>86.105106</td>\n",
       "      <td>87.863518</td>\n",
       "      <td>89.517852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.533118</td>\n",
       "      <td>90.304472</td>\n",
       "      <td>91.659844</td>\n",
       "      <td>92.740035</td>\n",
       "      <td>-</td>\n",
       "      <td>90.968871</td>\n",
       "      <td>86.457902</td>\n",
       "      <td>88.171255</td>\n",
       "      <td>89.868782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93.506105</td>\n",
       "      <td>90.191480</td>\n",
       "      <td>91.576739</td>\n",
       "      <td>92.694381</td>\n",
       "      <td>-</td>\n",
       "      <td>91.069886</td>\n",
       "      <td>86.806554</td>\n",
       "      <td>88.456725</td>\n",
       "      <td>90.050359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93.569093</td>\n",
       "      <td>90.329853</td>\n",
       "      <td>91.688686</td>\n",
       "      <td>92.767285</td>\n",
       "      <td>-</td>\n",
       "      <td>91.172702</td>\n",
       "      <td>86.839065</td>\n",
       "      <td>88.505276</td>\n",
       "      <td>90.309782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.518176</td>\n",
       "      <td>90.233668</td>\n",
       "      <td>91.609360</td>\n",
       "      <td>92.716422</td>\n",
       "      <td>-</td>\n",
       "      <td>91.774420</td>\n",
       "      <td>87.755571</td>\n",
       "      <td>89.362018</td>\n",
       "      <td>90.752327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93.588763</td>\n",
       "      <td>90.285149</td>\n",
       "      <td>91.664092</td>\n",
       "      <td>92.780848</td>\n",
       "      <td>-</td>\n",
       "      <td>90.962095</td>\n",
       "      <td>86.498312</td>\n",
       "      <td>88.240467</td>\n",
       "      <td>89.882497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93.548891</td>\n",
       "      <td>90.222823</td>\n",
       "      <td>91.608333</td>\n",
       "      <td>92.733376</td>\n",
       "      <td>-</td>\n",
       "      <td>91.443169</td>\n",
       "      <td>87.578594</td>\n",
       "      <td>89.156541</td>\n",
       "      <td>90.340302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>93.546935</td>\n",
       "      <td>90.267266</td>\n",
       "      <td>91.638870</td>\n",
       "      <td>92.745013</td>\n",
       "      <td>-</td>\n",
       "      <td>91.272700</td>\n",
       "      <td>87.017306</td>\n",
       "      <td>88.682254</td>\n",
       "      <td>90.228125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Precision  Train Recall  Train F1 Score  Train Accuracy  -  \\\n",
       "0              93.607940     90.317284       91.690165       92.821417  -   \n",
       "1              93.494421     90.196505       91.573797       92.689171  -   \n",
       "2              93.473626     90.160268       91.542717       92.667130  -   \n",
       "3              93.629213     90.431155       91.774967       92.840067  -   \n",
       "4              93.533118     90.304472       91.659844       92.740035  -   \n",
       "5              93.506105     90.191480       91.576739       92.694381  -   \n",
       "6              93.569093     90.329853       91.688686       92.767285  -   \n",
       "7              93.518176     90.233668       91.609360       92.716422  -   \n",
       "8              93.588763     90.285149       91.664092       92.780848  -   \n",
       "9              93.548891     90.222823       91.608333       92.733376  -   \n",
       "Average        93.546935     90.267266       91.638870       92.745013  -   \n",
       "\n",
       "         Test Precision  Test Recall  Test F1 Sccore  Test Accuracy  \n",
       "0             91.344666    87.186872       88.837091      90.341776  \n",
       "1             91.490494    87.227714       88.897341      90.418065  \n",
       "2             91.791245    87.717370       89.332314      90.799512  \n",
       "3             90.709453    86.105106       87.863518      89.517852  \n",
       "4             90.968871    86.457902       88.171255      89.868782  \n",
       "5             91.069886    86.806554       88.456725      90.050359  \n",
       "6             91.172702    86.839065       88.505276      90.309782  \n",
       "7             91.774420    87.755571       89.362018      90.752327  \n",
       "8             90.962095    86.498312       88.240467      89.882497  \n",
       "9             91.443169    87.578594       89.156541      90.340302  \n",
       "Average       91.272700    87.017306       88.682254      90.228125  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfKFold = pd.DataFrame({\n",
    "    \"Train Precision\" : [item['precision'] for item in train_error],\n",
    "    \"Train Recall\" : [item['recall'] for item in train_error],\n",
    "    \"Train F1 Score\" : [item['f1'] for item in train_error],\n",
    "    \"Train Accuracy\" : [item['accuracy'] for item in train_error],\n",
    "    \"-\" : ['-' for item in train_error],\n",
    "    \"Test Precision\" : [item['precision'] for item in validation_error],\n",
    "    \"Test Recall\" : [item['recall'] for item in validation_error],\n",
    "    \"Test F1 Sccore\" : [item['f1'] for item in validation_error],\n",
    "    \"Test Accuracy\" : [item['accuracy'] for item in validation_error],\n",
    "})\n",
    "additional = []\n",
    "for item in dfKFold:\n",
    "    if item != '-':\n",
    "        additional.append(dfKFold[item].mean())\n",
    "    else:\n",
    "        additional.append('-')\n",
    "dfKFold = pd.concat([dfKFold,pd.DataFrame(\n",
    "    [additional],\n",
    "    index=['Average'], columns=dfKFold.columns\n",
    ")])\n",
    "dfKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Best Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "searchRF = GridSearchCV(estimator = RandomForestClassifier(),\n",
    "                     param_grid = {\n",
    "                         'class_weight' : [{'Entertainment':2.74,'Business':3.70,'Technology':3.91,'Medical':9.24},None]\n",
    "                     }, scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m. khakim hidayad\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'class_weight': [{'Business': 3.7,\n",
       "                                           'Entertainment': 2.74,\n",
       "                                           'Medical': 9.24,\n",
       "                                           'Technology': 3.91},\n",
       "                                          None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchRF.fit(messages_tfidf, df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "                       class_weight={'Business': 3.7, 'Entertainment': 2.74,\n",
       "                                     'Medical': 9.24, 'Technology': 3.91},\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchRF.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = Pipeline([\n",
    "    ('bow', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', searchRF.best_estimator_),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None...\n",
       "                                                      'Entertainment': 2.74,\n",
       "                                                      'Medical': 9.24,\n",
       "                                                      'Technology': 3.91},\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRF.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.99      0.99      0.99     15910\n",
      "Entertainment       0.99      1.00      0.99     21570\n",
      "      Medical       1.00      0.99      0.99      6408\n",
      "   Technology       1.00      0.99      0.99     15094\n",
      "\n",
      "     accuracy                           0.99     58982\n",
      "    macro avg       0.99      0.99      0.99     58982\n",
      " weighted avg       0.99      0.99      0.99     58982\n",
      "\n",
      "Accuracy =  99.24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15815</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>21498</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>6326</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>11</td>\n",
       "      <td>14893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2      3\n",
       "0  15815     43    12     40\n",
       "1     48  21498     8     16\n",
       "2     31     44  6326      7\n",
       "3     99     91    11  14893"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = modelRF.predict(xTrain)\n",
    "print(classification_report(yTrain,prediction))\n",
    "print('Accuracy = ', round(accuracy_score(yTrain,prediction)*100,2))\n",
    "pd.DataFrame(confusion_matrix(yTrain, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.85      0.84      0.84      1797\n",
      "Entertainment       0.87      0.95      0.91      2391\n",
      "      Medical       0.91      0.78      0.84       683\n",
      "   Technology       0.88      0.82      0.85      1682\n",
      "\n",
      "     accuracy                           0.87      6553\n",
      "    macro avg       0.88      0.85      0.86      6553\n",
      " weighted avg       0.87      0.87      0.87      6553\n",
      "\n",
      "Accuracy =  86.92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1509</td>\n",
       "      <td>133</td>\n",
       "      <td>23</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>2264</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>74</td>\n",
       "      <td>536</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>132</td>\n",
       "      <td>13</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1    2     3\n",
       "0  1509   133   23   132\n",
       "1    63  2264   20    44\n",
       "2    56    74  536    17\n",
       "3   150   132   13  1387"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = modelRF.predict(xTest)\n",
    "print(classification_report(yTest,prediction))\n",
    "print('Accuracy = ', round(accuracy_score(yTest,prediction)*100,2))\n",
    "pd.DataFrame(confusion_matrix(yTest, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "data = df['News Title Processed']\n",
    "target = df['Category']\n",
    "train_error = []\n",
    "validation_error = []\n",
    "for trainIndex, valIndex in kf.split(data, target):\n",
    "    xTrain, xTest = data.iloc[trainIndex], data.iloc[valIndex]\n",
    "    yTrain, yTest = target.iloc[trainIndex], target.iloc[valIndex]\n",
    "    \n",
    "    trainError, valError = calculation_metrics(xTrain, yTrain, xTest, yTest, modelRF)\n",
    "    \n",
    "    train_error.append(trainError)\n",
    "    validation_error.append(valError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>-</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Tesbt Recall</th>\n",
       "      <th>Test F1 Sccore</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.245690</td>\n",
       "      <td>99.141241</td>\n",
       "      <td>99.192369</td>\n",
       "      <td>99.260779</td>\n",
       "      <td>-</td>\n",
       "      <td>86.388236</td>\n",
       "      <td>84.981960</td>\n",
       "      <td>85.612725</td>\n",
       "      <td>86.985047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.331641</td>\n",
       "      <td>99.214639</td>\n",
       "      <td>99.272269</td>\n",
       "      <td>99.301470</td>\n",
       "      <td>-</td>\n",
       "      <td>86.811729</td>\n",
       "      <td>85.011923</td>\n",
       "      <td>85.793283</td>\n",
       "      <td>87.076594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.254847</td>\n",
       "      <td>99.132664</td>\n",
       "      <td>99.192588</td>\n",
       "      <td>99.259083</td>\n",
       "      <td>-</td>\n",
       "      <td>86.843716</td>\n",
       "      <td>85.069504</td>\n",
       "      <td>85.815386</td>\n",
       "      <td>87.137626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.313481</td>\n",
       "      <td>99.174280</td>\n",
       "      <td>99.242744</td>\n",
       "      <td>99.284515</td>\n",
       "      <td>-</td>\n",
       "      <td>86.985184</td>\n",
       "      <td>85.125199</td>\n",
       "      <td>85.913713</td>\n",
       "      <td>87.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.212078</td>\n",
       "      <td>98.994565</td>\n",
       "      <td>99.101491</td>\n",
       "      <td>99.167529</td>\n",
       "      <td>-</td>\n",
       "      <td>87.489156</td>\n",
       "      <td>85.014542</td>\n",
       "      <td>86.038517</td>\n",
       "      <td>86.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.261255</td>\n",
       "      <td>99.093106</td>\n",
       "      <td>99.175763</td>\n",
       "      <td>99.248923</td>\n",
       "      <td>-</td>\n",
       "      <td>86.020341</td>\n",
       "      <td>84.747875</td>\n",
       "      <td>85.266985</td>\n",
       "      <td>86.433694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99.305587</td>\n",
       "      <td>99.119327</td>\n",
       "      <td>99.210976</td>\n",
       "      <td>99.267573</td>\n",
       "      <td>-</td>\n",
       "      <td>86.640203</td>\n",
       "      <td>84.223875</td>\n",
       "      <td>85.248086</td>\n",
       "      <td>86.677857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99.305524</td>\n",
       "      <td>99.150232</td>\n",
       "      <td>99.226790</td>\n",
       "      <td>99.294700</td>\n",
       "      <td>-</td>\n",
       "      <td>87.114176</td>\n",
       "      <td>85.326317</td>\n",
       "      <td>86.093862</td>\n",
       "      <td>87.059362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99.266077</td>\n",
       "      <td>99.104423</td>\n",
       "      <td>99.183610</td>\n",
       "      <td>99.240446</td>\n",
       "      <td>-</td>\n",
       "      <td>86.922000</td>\n",
       "      <td>85.149718</td>\n",
       "      <td>85.925443</td>\n",
       "      <td>86.967801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.281652</td>\n",
       "      <td>99.206153</td>\n",
       "      <td>99.242830</td>\n",
       "      <td>99.284527</td>\n",
       "      <td>-</td>\n",
       "      <td>86.807777</td>\n",
       "      <td>84.915958</td>\n",
       "      <td>85.749799</td>\n",
       "      <td>86.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>99.277783</td>\n",
       "      <td>99.133063</td>\n",
       "      <td>99.204143</td>\n",
       "      <td>99.260955</td>\n",
       "      <td>-</td>\n",
       "      <td>86.802252</td>\n",
       "      <td>84.956687</td>\n",
       "      <td>85.745780</td>\n",
       "      <td>86.912329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Precision  Train Recall  Train F1 Score  Train Accuracy  -  \\\n",
       "0              99.245690     99.141241       99.192369       99.260779  -   \n",
       "1              99.331641     99.214639       99.272269       99.301470  -   \n",
       "2              99.254847     99.132664       99.192588       99.259083  -   \n",
       "3              99.313481     99.174280       99.242744       99.284515  -   \n",
       "4              99.212078     98.994565       99.101491       99.167529  -   \n",
       "5              99.261255     99.093106       99.175763       99.248923  -   \n",
       "6              99.305587     99.119327       99.210976       99.267573  -   \n",
       "7              99.305524     99.150232       99.226790       99.294700  -   \n",
       "8              99.266077     99.104423       99.183610       99.240446  -   \n",
       "9              99.281652     99.206153       99.242830       99.284527  -   \n",
       "Average        99.277783     99.133063       99.204143       99.260955  -   \n",
       "\n",
       "         Test Precision  Tesbt Recall  Test F1 Sccore  Test Accuracy  \n",
       "0             86.388236     84.981960       85.612725      86.985047  \n",
       "1             86.811729     85.011923       85.793283      87.076594  \n",
       "2             86.843716     85.069504       85.815386      87.137626  \n",
       "3             86.985184     85.125199       85.913713      87.000305  \n",
       "4             87.489156     85.014542       86.038517      86.893500  \n",
       "5             86.020341     84.747875       85.266985      86.433694  \n",
       "6             86.640203     84.223875       85.248086      86.677857  \n",
       "7             87.114176     85.326317       86.093862      87.059362  \n",
       "8             86.922000     85.149718       85.925443      86.967801  \n",
       "9             86.807777     84.915958       85.749799      86.891500  \n",
       "Average       86.802252     84.956687       85.745780      86.912329  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfKFold = pd.DataFrame({\n",
    "    \"Train Precision\" : [item['precision'] for item in train_error],\n",
    "    \"Train Recall\" : [item['recall'] for item in train_error],\n",
    "    \"Train F1 Score\" : [item['f1'] for item in train_error],\n",
    "    \"Train Accuracy\" : [item['accuracy'] for item in train_error],\n",
    "    \"-\" : ['-' for item in train_error],\n",
    "    \"Test Precision\" : [item['precision'] for item in validation_error],\n",
    "    \"Tesbt Recall\" : [item['recall'] for item in validation_error],\n",
    "    \"Test F1 Sccore\" : [item['f1'] for item in validation_error],\n",
    "    \"Test Accuracy\" : [item['accuracy'] for item in validation_error],\n",
    "})\n",
    "additional = []\n",
    "for item in dfKFold:\n",
    "    if item != '-':\n",
    "        additional.append(dfKFold[item].mean())\n",
    "    else:\n",
    "        additional.append('-')\n",
    "dfKFold = pd.concat([dfKFold,pd.DataFrame(\n",
    "    [additional],\n",
    "    index=['Average'], columns=dfKFold.columns\n",
    ")])\n",
    "dfKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biuld Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "modelSVC = Pipeline([\n",
    "    ('bow', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSVC.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.97      0.97      0.97     15910\n",
      "Entertainment       0.99      0.99      0.99     21570\n",
      "      Medical       0.99      0.98      0.98      6408\n",
      "   Technology       0.97      0.97      0.97     15094\n",
      "\n",
      "     accuracy                           0.98     58982\n",
      "    macro avg       0.98      0.98      0.98     58982\n",
      " weighted avg       0.98      0.98      0.98     58982\n",
      "\n",
      "Accuracy =  98.07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15410</td>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>21446</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>6287</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>314</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>14703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2      3\n",
       "0  15410     56    46    398\n",
       "1     61  21446    14     49\n",
       "2     70     32  6287     19\n",
       "3    314     64    13  14703"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = modelSVC.predict(xTrain)\n",
    "print(classification_report(yTrain,prediction))\n",
    "print('Accuracy = ', round(accuracy_score(yTrain,prediction)*100,2))\n",
    "pd.DataFrame(confusion_matrix(yTrain, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Business       0.91      0.88      0.90      1797\n",
      "Entertainment       0.96      0.97      0.97      2391\n",
      "      Medical       0.93      0.90      0.91       683\n",
      "   Technology       0.89      0.92      0.91      1682\n",
      "\n",
      "     accuracy                           0.93      6553\n",
      "    macro avg       0.92      0.92      0.92      6553\n",
      " weighted avg       0.93      0.93      0.93      6553\n",
      "\n",
      "Accuracy =  92.61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1587</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>2316</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>614</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>1552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1    2     3\n",
       "0  1587    44   23   143\n",
       "1    29  2316   12    34\n",
       "2    39    15  614    15\n",
       "3    92    26   12  1552"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = modelSVC.predict(xTest)\n",
    "print(classification_report(yTest,prediction))\n",
    "print('Accuracy = ', round(accuracy_score(yTest,prediction)*100,2))\n",
    "pd.DataFrame(confusion_matrix(yTest, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "data = df['News Title Processed']\n",
    "target = df['Category']\n",
    "train_error = []\n",
    "validation_error = []\n",
    "for trainIndex, valIndex in kf.split(data, target):\n",
    "    xTrain, xTest = data.iloc[trainIndex], data.iloc[valIndex]\n",
    "    yTrain, yTest = target.iloc[trainIndex], target.iloc[valIndex]\n",
    "    \n",
    "    trainError, valError = calculation_metrics(xTrain, yTrain, xTest, yTest, modelSVC)\n",
    "    \n",
    "    train_error.append(trainError)\n",
    "    validation_error.append(valError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>-</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Tesbt Recall</th>\n",
       "      <th>Test F1 Sccore</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.078330</td>\n",
       "      <td>97.992379</td>\n",
       "      <td>98.034884</td>\n",
       "      <td>98.085824</td>\n",
       "      <td>-</td>\n",
       "      <td>92.917284</td>\n",
       "      <td>91.818848</td>\n",
       "      <td>92.336836</td>\n",
       "      <td>92.889838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.042789</td>\n",
       "      <td>97.939964</td>\n",
       "      <td>97.990910</td>\n",
       "      <td>98.046829</td>\n",
       "      <td>-</td>\n",
       "      <td>92.903415</td>\n",
       "      <td>92.054842</td>\n",
       "      <td>92.461756</td>\n",
       "      <td>92.996643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.076351</td>\n",
       "      <td>97.968115</td>\n",
       "      <td>98.021736</td>\n",
       "      <td>98.072261</td>\n",
       "      <td>-</td>\n",
       "      <td>93.318331</td>\n",
       "      <td>92.553798</td>\n",
       "      <td>92.920031</td>\n",
       "      <td>93.454379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.055213</td>\n",
       "      <td>97.961369</td>\n",
       "      <td>98.007895</td>\n",
       "      <td>98.070565</td>\n",
       "      <td>-</td>\n",
       "      <td>92.364050</td>\n",
       "      <td>91.703183</td>\n",
       "      <td>92.021599</td>\n",
       "      <td>92.538908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.083407</td>\n",
       "      <td>97.983213</td>\n",
       "      <td>98.032875</td>\n",
       "      <td>98.089215</td>\n",
       "      <td>-</td>\n",
       "      <td>92.503927</td>\n",
       "      <td>91.835493</td>\n",
       "      <td>92.158099</td>\n",
       "      <td>92.783033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98.037804</td>\n",
       "      <td>97.931009</td>\n",
       "      <td>97.983874</td>\n",
       "      <td>98.051948</td>\n",
       "      <td>-</td>\n",
       "      <td>92.855027</td>\n",
       "      <td>92.270461</td>\n",
       "      <td>92.553167</td>\n",
       "      <td>92.949794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>98.104026</td>\n",
       "      <td>98.000691</td>\n",
       "      <td>98.051916</td>\n",
       "      <td>98.099420</td>\n",
       "      <td>-</td>\n",
       "      <td>92.462066</td>\n",
       "      <td>92.014083</td>\n",
       "      <td>92.230701</td>\n",
       "      <td>92.919274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>98.018610</td>\n",
       "      <td>97.919784</td>\n",
       "      <td>97.968791</td>\n",
       "      <td>98.029907</td>\n",
       "      <td>-</td>\n",
       "      <td>92.676439</td>\n",
       "      <td>91.919255</td>\n",
       "      <td>92.282903</td>\n",
       "      <td>92.842973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>98.050947</td>\n",
       "      <td>97.962334</td>\n",
       "      <td>98.006237</td>\n",
       "      <td>98.072293</td>\n",
       "      <td>-</td>\n",
       "      <td>92.369544</td>\n",
       "      <td>91.670808</td>\n",
       "      <td>92.008426</td>\n",
       "      <td>92.583550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98.067423</td>\n",
       "      <td>97.950938</td>\n",
       "      <td>98.008600</td>\n",
       "      <td>98.073989</td>\n",
       "      <td>-</td>\n",
       "      <td>92.295409</td>\n",
       "      <td>91.836428</td>\n",
       "      <td>92.047813</td>\n",
       "      <td>92.614070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>98.061490</td>\n",
       "      <td>97.960980</td>\n",
       "      <td>98.010772</td>\n",
       "      <td>98.069225</td>\n",
       "      <td>-</td>\n",
       "      <td>92.666549</td>\n",
       "      <td>91.967720</td>\n",
       "      <td>92.302133</td>\n",
       "      <td>92.857246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Precision  Train Recall  Train F1 Score  Train Accuracy  -  \\\n",
       "0              98.078330     97.992379       98.034884       98.085824  -   \n",
       "1              98.042789     97.939964       97.990910       98.046829  -   \n",
       "2              98.076351     97.968115       98.021736       98.072261  -   \n",
       "3              98.055213     97.961369       98.007895       98.070565  -   \n",
       "4              98.083407     97.983213       98.032875       98.089215  -   \n",
       "5              98.037804     97.931009       97.983874       98.051948  -   \n",
       "6              98.104026     98.000691       98.051916       98.099420  -   \n",
       "7              98.018610     97.919784       97.968791       98.029907  -   \n",
       "8              98.050947     97.962334       98.006237       98.072293  -   \n",
       "9              98.067423     97.950938       98.008600       98.073989  -   \n",
       "Average        98.061490     97.960980       98.010772       98.069225  -   \n",
       "\n",
       "         Test Precision  Tesbt Recall  Test F1 Sccore  Test Accuracy  \n",
       "0             92.917284     91.818848       92.336836      92.889838  \n",
       "1             92.903415     92.054842       92.461756      92.996643  \n",
       "2             93.318331     92.553798       92.920031      93.454379  \n",
       "3             92.364050     91.703183       92.021599      92.538908  \n",
       "4             92.503927     91.835493       92.158099      92.783033  \n",
       "5             92.855027     92.270461       92.553167      92.949794  \n",
       "6             92.462066     92.014083       92.230701      92.919274  \n",
       "7             92.676439     91.919255       92.282903      92.842973  \n",
       "8             92.369544     91.670808       92.008426      92.583550  \n",
       "9             92.295409     91.836428       92.047813      92.614070  \n",
       "Average       92.666549     91.967720       92.302133      92.857246  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfKFold = pd.DataFrame({\n",
    "    \"Train Precision\" : [item['precision'] for item in train_error],\n",
    "    \"Train Recall\" : [item['recall'] for item in train_error],\n",
    "    \"Train F1 Score\" : [item['f1'] for item in train_error],\n",
    "    \"Train Accuracy\" : [item['accuracy'] for item in train_error],\n",
    "    \"-\" : ['-' for item in train_error],\n",
    "    \"Test Precision\" : [item['precision'] for item in validation_error],\n",
    "    \"Tesbt Recall\" : [item['recall'] for item in validation_error],\n",
    "    \"Test F1 Sccore\" : [item['f1'] for item in validation_error],\n",
    "    \"Test Accuracy\" : [item['accuracy'] for item in validation_error],\n",
    "})\n",
    "additional = []\n",
    "for item in dfKFold:\n",
    "    if item != '-':\n",
    "        additional.append(dfKFold[item].mean())\n",
    "    else:\n",
    "        additional.append('-')\n",
    "dfKFold = pd.concat([dfKFold,pd.DataFrame(\n",
    "    [additional],\n",
    "    index=['Average'], columns=dfKFold.columns\n",
    ")])\n",
    "dfKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on 3 model that we already build, LinearSVC have the highest score in term of precission, recall and accuracy. So we are going to choose LinearSVC as our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can do prediction through this link http://khakimh-nlp.herokuapp.com/. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE : \n",
    "> <br>It might be take a while to connect since we are using free hosting app from heroku and they are set the app to sleep after 30 minutes unused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can send json file using this format:\n",
    "```sh\n",
    "{\n",
    "    \"text\" : your_title,\n",
    "    \"type\" : \"news\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and it will return something like:\n",
    "```sh\n",
    "{\n",
    "    \"prediction\": prediction\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
